{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESG-related content extracted and saved to: ESG_Content_Extracted.txt\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "\n",
    "# Define ESG-related keywords\n",
    "esg_keywords = [\n",
    "    \"ESG\", \"Environmental\", \"Social\", \"Governance\",\n",
    "    \"Sustainability\", \"Climate\", \"Carbon\", \"Diversity\",\n",
    "    \"Equity\", \"Inclusion\", \"Social Impact\", \"Emissions\",\n",
    "    \"Water Stewardship\", \"Waste Reduction\", \"Renewable\",\n",
    "    \"Human Rights\", \"Corporate Responsibility\"\n",
    "]\n",
    "\n",
    "# Path to the annual report PDF\n",
    "pdf_path = \"2024-Annual-Report.pdf\"\n",
    "\n",
    "# Function to extract ESG-related text\n",
    "def extract_esg_content(pdf_path, keywords):\n",
    "    esg_content = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                for keyword in keywords:\n",
    "                    if keyword.lower() in text.lower():\n",
    "                        esg_content.append(text)\n",
    "                        break  # Avoid duplicate entries from the same page\n",
    "    return esg_content\n",
    "\n",
    "# Extract ESG content\n",
    "esg_data = extract_esg_content(pdf_path, esg_keywords)\n",
    "\n",
    "# Save extracted content to a text file\n",
    "output_path = \"ESG_Content_Extracted.txt\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"\\n\\n\".join(esg_data))\n",
    "\n",
    "# Output file location\n",
    "print(f\"ESG-related content extracted and saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ESG-related content...\n",
      "Applying Named Entity Recognition (NER)...\n",
      "Extraction complete. Data saved to Extracted_ESG_Entities.csv\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import spacy\n",
    "import pandas as pd\n",
    "\n",
    "# Load the spaCy NER model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Define ESG-related keywords\n",
    "esg_keywords = [\n",
    "    \"ESG\", \"Environmental\", \"Social\", \"Governance\",\n",
    "    \"Sustainability\", \"Climate\", \"Carbon\", \"Diversity\",\n",
    "    \"Equity\", \"Inclusion\", \"Social Impact\", \"Emissions\",\n",
    "    \"Water Stewardship\", \"Waste Reduction\", \"Renewable\",\n",
    "    \"Human Rights\", \"Corporate Responsibility\"\n",
    "]\n",
    "\n",
    "# Function to extract ESG-related text from the PDF\n",
    "def extract_esg_text(pdf_path, keywords):\n",
    "    esg_text = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                for keyword in keywords:\n",
    "                    if keyword.lower() in text.lower():\n",
    "                        esg_text.append(text)\n",
    "                        break  # Avoid duplicate entries from the same page\n",
    "    return \" \".join(esg_text)  # Combine all ESG-related text\n",
    "\n",
    "# Function to apply Named Entity Recognition (NER)\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = {\"Organization\": [], \"Location\": [], \"Regulation\": []}\n",
    "\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == \"ORG\":\n",
    "            entities[\"Organization\"].append(ent.text)\n",
    "        elif ent.label_ == \"GPE\":\n",
    "            entities[\"Location\"].append(ent.text)\n",
    "        elif ent.label_ == \"LAW\":\n",
    "            entities[\"Regulation\"].append(ent.text)\n",
    "\n",
    "    # Remove duplicates\n",
    "    for key in entities:\n",
    "        entities[key] = list(set(entities[key]))\n",
    "\n",
    "    return entities\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    pdf_path = \"2024-Annual-Report.pdf\"  # Change to your file path\n",
    "    print(\"Extracting ESG-related content...\")\n",
    "    esg_text = extract_esg_text(pdf_path, esg_keywords)\n",
    "\n",
    "    if not esg_text:\n",
    "        print(\"No ESG-related content found in the document.\")\n",
    "        return\n",
    "\n",
    "    print(\"Applying Named Entity Recognition (NER)...\")\n",
    "    extracted_entities = extract_entities(esg_text)\n",
    "\n",
    "    # Convert extracted data into a DataFrame\n",
    "    df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in extracted_entities.items()]))\n",
    "\n",
    "    # Save to CSV\n",
    "    output_csv = \"Extracted_ESG_Entities.csv\"\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Extraction complete. Data saved to {output_csv}\")\n",
    "\n",
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting ESG-related content...\n",
      "\n",
      "Summarizing key ESG insights...\n",
      "\n",
      "Summary Preview:\n",
      "\n",
      "The Walt Disney Company and SUBSIDIARIES report on its financial condition and results of operations for the year ended December 31, 2013. The report includes the following sections: Risk Factors, Legal Proceedings, Properties, Mine Safety Disclosures, Information About our Executive Officers and Corporate Governance. The table of contents of the report is divided into the following parts: Table of Contents.\n",
      "The Walt Disney Company, together with the subsidiaries through which businesses are conducted (the Company), is a diversified worldwide entertainment company with operations in three segments: Entertainment, Sports and Experiences. The Entertainment segment generally encompasses the Company’s non-sports focused global film and episodic content production and distribution activities. The terms “Company”, ‘we’, “our” and “us” are used in this report to refer collectively to the parent company and the subsidiaries.\n",
      "The company owns ABC Television Network, Freeform, FX and National Ge\n",
      "\n",
      "Summary saved to: ESG_Summary.txt\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import textwrap\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load NLP summarization model\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Define ESG-related keywords\n",
    "esg_keywords = [\n",
    "    \"ESG\", \"Environmental\", \"Social\", \"Governance\",\n",
    "    \"Sustainability\", \"Climate\", \"Carbon\", \"Diversity\",\n",
    "    \"Equity\", \"Inclusion\", \"Social Impact\", \"Emissions\",\n",
    "    \"Water Stewardship\", \"Waste Reduction\", \"Renewable\",\n",
    "    \"Human Rights\", \"Corporate Responsibility\"\n",
    "]\n",
    "\n",
    "# Extract ESG-related text from the PDF\n",
    "def extract_esg_text(pdf_path, keywords):\n",
    "    esg_text = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                for keyword in keywords:\n",
    "                    if keyword.lower() in text.lower():\n",
    "                        esg_text.append(text)\n",
    "                        break  # Avoid duplicate entries\n",
    "    return \" \".join(esg_text)  # Combine all ESG-related text\n",
    "\n",
    "# Summarize extracted ESG content with precise control\n",
    "def summarize_text(text):\n",
    "    if len(text.split()) < 50:  # If the content is too short, return as-is\n",
    "        return text\n",
    "\n",
    "    wrapped_text = textwrap.wrap(text, width=1024)  # Avoid input size issues\n",
    "    summary = []\n",
    "\n",
    "    for chunk in wrapped_text:\n",
    "        # Adjust max_length dynamically based on input size\n",
    "        words = len(chunk.split())\n",
    "        max_len = min(words, 150)  # Limit summary to max 150 words\n",
    "        min_len = max(50, max_len // 2)  # Ensure meaningful summary\n",
    "        \n",
    "        result = summarizer(chunk, max_length=max_len, min_length=min_len, do_sample=False)\n",
    "        summary.append(result[0]['summary_text'])\n",
    "\n",
    "    return \"\\n\".join(summary)\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    pdf_path = \"2024-Annual-Report.pdf\"  # Update with your actual file path\n",
    "    print(\"\\nExtracting ESG-related content...\\n\")\n",
    "    esg_text = extract_esg_text(pdf_path, esg_keywords)\n",
    "\n",
    "    if not esg_text:\n",
    "        print(\"No ESG-related content found.\")\n",
    "        return\n",
    "\n",
    "    print(\"Summarizing key ESG insights...\\n\")\n",
    "    summary = summarize_text(esg_text)\n",
    "\n",
    "    # Save summary to a text file\n",
    "    output_txt = \"ESG_Summary.txt\"\n",
    "    with open(output_txt, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(summary)\n",
    "\n",
    "    # Print preview of output\n",
    "    print(\"Summary Preview:\\n\")\n",
    "    print(summary[:1000])  # Print first 1000 characters for preview\n",
    "    print(f\"\\nSummary saved to: {output_txt}\")\n",
    "\n",
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from transformers import pipeline\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load NLP models\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Define ESG-related keywords\n",
    "esg_keywords = [\n",
    "    \"ESG\", \"Environmental\", \"Social\", \"Governance\",\n",
    "    \"Sustainability\", \"Climate\", \"Carbon\", \"Diversity\",\n",
    "    \"Equity\", \"Inclusion\", \"Social Impact\", \"Emissions\",\n",
    "    \"Water Stewardship\", \"Waste Reduction\", \"Renewable\",\n",
    "    \"Human Rights\", \"Corporate Responsibility\"\n",
    "]\n",
    "\n",
    "# Extract ESG-related text from the PDF\n",
    "def extract_esg_text(pdf_path, keywords):\n",
    "    esg_text = []\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                for keyword in keywords:\n",
    "                    if keyword.lower() in text.lower():\n",
    "                        esg_text.append(text)\n",
    "                        break\n",
    "    return \" \".join(esg_text)  # Combine ESG text\n",
    "\n",
    "# Count occurrences of ESG-related terms\n",
    "def count_esg_terms(text):\n",
    "    words = text.split()\n",
    "    word_counts = Counter(word.lower() for word in words if word.lower() in esg_keywords)\n",
    "    return word_counts.most_common(5)  # Top 5 ESG terms\n",
    "\n",
    "# Extract named entities\n",
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entity_counts = Counter()\n",
    "    \n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in [\"ORG\", \"GPE\", \"LAW\"]:\n",
    "            entity_counts[ent.text] += 1\n",
    "    \n",
    "    return entity_counts.most_common(5)  # Top 5 entities\n",
    "\n",
    "# Perform sentiment analysis\n",
    "def analyze_sentiment(text):\n",
    "    blob = TextBlob(text)\n",
    "    sentiment_score = blob.sentiment.polarity\n",
    "    \n",
    "    if sentiment_score > 0.1:\n",
    "        return \"Positive Sentiment\"\n",
    "    elif sentiment_score < -0.1:\n",
    "        return \"Negative Sentiment\"\n",
    "    else:\n",
    "        return \"Neutral Sentiment\"\n",
    "\n",
    "# Summarize ESG insights\n",
    "def summarize_esg(text):\n",
    "    if len(text.split()) < 50:\n",
    "        return text  # Return as-is if too short\n",
    "\n",
    "    summary = summarizer(text, max_length=150, min_length=50, do_sample=False)\n",
    "    return summary[0]['summary_text']\n",
    "\n",
    "# Generate structured output in Markdown format\n",
    "def generate_output(pdf_path):\n",
    "    print(\"Extracting ESG-related content...\\n\")\n",
    "    esg_text = extract_esg_text(pdf_path, esg_keywords)\n",
    "\n",
    "    if not esg_text:\n",
    "        print(\"No ESG-related content found.\")\n",
    "        return\n",
    "\n",
    "    # Compute results\n",
    "    esg_terms = count_esg_terms(esg_text)\n",
    "    named_entities = extract_entities(esg_text)\n",
    "    sentiment = analyze_sentiment(esg_text)\n",
    "    esg_summary = summarize_esg(esg_text)\n",
    "\n",
    "     # Format output properly for Markdown\n",
    "    output = f\"\"\"\n",
    "### 1. Most Common ESG Terms Found\n",
    "```diff\n",
    "{\"\".join(f\"- {term.capitalize()}: {count} occurrences\\n\" for term, count in esg_terms)}\"\"\"\n",
    "    {\"\".join(f\"- {entity} ({count} mentions)\\n\" for entity, count in named_entities)}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
